{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "625db41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44eb0c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from the file\n",
    "with open(\"IE506_2024_progchallenge_train.txt\", \"r\") as file:\n",
    "    lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55c7c6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract main classes, subclasses, and feature-value pairs\n",
    "main_classes = [line.split()[0].split(\":\")[1] for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fab64fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "subclasses = [line.split()[1].split(\":\")[1] for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd2d4f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f2f2db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert main_classes and subclasses to lists of lists\n",
    "main_classes = [classes.split(',') for classes in main_classes]\n",
    "subclasses = [classes.split(',') for classes in subclasses]\n",
    "\n",
    "# Encode main class labels\n",
    "mlb_main = MultiLabelBinarizer()\n",
    "y_train_main_encoded = mlb_main.fit_transform(main_classes)\n",
    "\n",
    "# Encode subclass labels\n",
    "mlb_sub = MultiLabelBinarizer()\n",
    "y_train_sub_encoded = mlb_sub.fit_transform(subclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6da5b450",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "values = []\n",
    "data_point_indices = []\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    parts = line.split()\n",
    "    for part in parts[2:]:\n",
    "        index, value = map(float, part.split(\":\"))\n",
    "        indices.append(index)\n",
    "        values.append(value)\n",
    "        data_point_indices.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c420d73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to numpy arrays\n",
    "indices = np.array(indices, dtype=int)\n",
    "values = np.array(values)\n",
    "data_point_indices = np.array(data_point_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cc4fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Determine image dimensions\n",
    "num_images = len(set(data_point_indices))\n",
    "max_index = max(indices)\n",
    "image_size = int(max_index) + 1  # Assuming indices start from 0\n",
    "\n",
    "# Create empty arrays to store image data\n",
    "images = np.zeros((num_images, image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9db41aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill image data arrays\n",
    "for idx, value, data_idx in zip(indices, values, data_point_indices):\n",
    "    images[data_idx, int(idx)] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a78447a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random indices for the training set\n",
    "train_indices = np.random.choice(200000, size=160000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "explicit-discovery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/23n0452/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/23n0452/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: numpy in /home/23n0452/.local/lib/python3.9/site-packages (1.24.4)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/23n0452/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/23n0452/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/23n0452/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -vidia-nccl-cu12 (/home/23n0452/.local/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "601e6f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean mask for the test set\n",
    "test_mask = np.ones(200000, dtype=bool)\n",
    "test_mask[train_indices] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea9b073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "X_train = images[train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b274c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_main = y_train_main_encoded[train_indices]\n",
    "Y_train_sub = y_train_sub_encoded[train_indices]\n",
    "\n",
    "X_test = images[test_mask]\n",
    "Y_test_main = y_train_main_encoded[test_mask]\n",
    "Y_test_sub = y_train_sub_encoded[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8522d760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape,Y_train_main.shape,Y_train_sub.shape,X_test.shape,Y_test_main.shape,Y_test_sub.shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91808081",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Convert sparse matrices to CSR format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cd118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = csr_matrix(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb9fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_csr = csr_matrix(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6dd0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_csr = csr_matrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eade255",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_csr,X_test_csr,Y_train_main.shape,Y_train_sub.shape,Y_test_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d4c9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4503b459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "# Define hyperparameters for Logistic Regression model for main class\n",
    "best_params_main = {\n",
    "    'C': 1.0,               # Regularization strength\n",
    "    'penalty': 'l2',        # Penalty term\n",
    "    'solver': 'liblinear',  # Solver algorithm\n",
    "    'class_weight': 'balanced'  # Class weight\n",
    "}\n",
    "\n",
    "# Initialize Logistic Regression model for main class with best parameters\n",
    "logistic_model_main = LogisticRegression(max_iter=1000, **best_params_main)\n",
    "\n",
    "# Wrap the logistic regression model with MultiOutputClassifier for main class and sub-classes\n",
    "multi_target_logistic_main = MultiOutputClassifier(logistic_model_main)\n",
    "\n",
    "# Fit the main class model with X_train and y_train_main_encoded\n",
    "multi_target_logistic_main.fit(X, y_train_main_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d567786c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for main class\n",
    "predictions_main = multi_target_logistic_main.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a757848",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e021f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9281784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "# Concatenate predictions_main with X_train_csr\n",
    "X_with_predictions = hstack((X, predictions_main))\n",
    "\n",
    "X_with_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456b7dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters for Logistic Regression model for sub-classes\n",
    "best_params_sub = {\n",
    "    'C': 1.0,               # Regularization strength\n",
    "    'penalty': 'l2',        # Penalty term\n",
    "    'solver': 'liblinear',  # Solver algorithm\n",
    "    'class_weight': 'balanced'  # Class weight\n",
    "}\n",
    "\n",
    "# Initialize Logistic Regression model for sub-classes with best parameters\n",
    "logistic_model_sub = LogisticRegression(max_iter=1000, **best_params_sub)\n",
    "\n",
    "# Wrap the logistic regression model with MultiOutputClassifier for sub-classes\n",
    "multi_target_logistic_sub = MultiOutputClassifier(logistic_model_sub)\n",
    "\n",
    "# Fit the subclass model with X_train and y_train_sub_encoded\n",
    "multi_target_logistic_sub.fit(X_with_predictions, y_train_sub_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b5fe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Get predictions for subclass\n",
    "predictions_sub = multi_target_logistic_sub.predict(X_with_predictions)\n",
    "\n",
    "# Now you have predictions for both main class and subclass\n",
    "# predictions_main contains predictions for the main class\n",
    "# predictions_sub contains predictions for the subclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6907f75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from the file\n",
    "with open(\"IE506_2024_progchallenge_test.txt\", \"r\") as file:\n",
    "    lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5093039",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_test = []\n",
    "values_test = []\n",
    "data_point_indices_test = []\n",
    "\n",
    "for i, line in enumerate(lines):\n",
    "    parts = line.split()\n",
    "    for part in parts[2:]:\n",
    "        index, value = map(float, part.split(\":\"))\n",
    "        indices_test.append(index)\n",
    "        values_test.append(value)\n",
    "        data_point_indices_test.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f20922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert lists to numpy arrays\n",
    "indices_test = np.array(indices_test, dtype=int)\n",
    "values_test = np.array(values_test)\n",
    "data_point_indices_test = np.array(data_point_indices_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afa67a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Determine image dimensions\n",
    "num_images = len(set(data_point_indices_test))\n",
    "max_index = max(indices_test)\n",
    "image_size = int(max_index) + 1  # Assuming indices start from 0\n",
    "\n",
    "# Create empty arrays to store image data\n",
    "images = np.zeros((num_images, image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce47789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill image data arrays\n",
    "for idx, value, data_idx in zip(indices_test, values_test, data_point_indices_test):\n",
    "    images[data_idx, int(idx)] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed8e2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = csr_matrix(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd57138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for main labels\n",
    "y_pred_main_images = multi_target_logistic_main.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-audience",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_main_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "# Concatenate predictions_main with X_train_csr\n",
    "images_with_predictions = hstack((images, y_pred_main_images))\n",
    "\n",
    "images_with_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cbdfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict for sub labels\n",
    "y_pred_sub_images = multi_target_logistic_sub.predict(images_with_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4d7191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode predicted main class labels\n",
    "y_pred_main_decoded = mlb_main.inverse_transform(y_pred_main_images)\n",
    "\n",
    "# Decode predicted subclass labels\n",
    "y_pred_sub_decoded = mlb_sub.inverse_transform(y_pred_sub_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c446069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_main_decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a502b64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame with the predicted labels\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': range(len(y_pred_main_images)),  # IDs starting from 0 to N_t-1\n",
    "    'M': [\"['\" + \"','\".join(map(str, labels)) + \"']\" for labels in y_pred_main_decoded],  # Format main labels\n",
    "    'S': [\"['\" + \"','\".join(map(str, labels)) + \"']\" for labels in y_pred_sub_decoded],   # Format sub labels\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "submission_df.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db1d2d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
